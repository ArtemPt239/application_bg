{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908d4f07-a127-4c8f-8c77-ebb423c33ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from matplotlib.image import imread\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms.functional as fn\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "from torch import nn, Tensor\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a42bb-83e3-4726-8b33-90acec5d1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/local/tmp/BostonGene_application_data/images/\"\n",
    "processed_image_size = 64\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e396adf-89ca-4379-bb0d-1557b598cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = os.listdir(dataset_dir)\n",
    "_filenames = {target:[file for file in os.listdir(f\"{dataset_dir}/{target}\")] for target in targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb74d8a-b019-48b3-a78d-d31822c72682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(filename: str) -> torch.Tensor:\n",
    "    # Load the image\n",
    "    raw_image = torch.tensor(imread(filename), dtype=torch.float32).permute(2, 1, 0)\n",
    "    # Crop it to the square shape\n",
    "    cropped_image = fn.center_crop(raw_image, output_size=min(raw_image.shape[1:]))\n",
    "    # Resize image\n",
    "    resized_image = fn.resize(cropped_image, size=processed_image_size)\n",
    "    # Normalise image\n",
    "    normalised_image = resized_image / 255\n",
    "    return normalised_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6873a-ba8d-431b-9cc2-00ec8996170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = f\"{dataset_dir}/{targets[0]}/{_filenames[targets[0]][3]}\"\n",
    "print(\"Before:\")\n",
    "plt.imshow(imread(img_name))\n",
    "plt.show()\n",
    "print(\"After:\")\n",
    "plt.imshow(load_and_preprocess(img_name).permute(2, 1, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64462c7-46a5-42ad-bb78-d5125eaca139",
   "metadata": {},
   "source": [
    "Building the dataset and splitting the data\n",
    "\n",
    "Processed dataset is small, so we can easilly fit it inside ram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a59f8d-a675-400c-bcdf-7c851814f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoding = {targets[_id]: _id for _id in range(len(targets))}\n",
    "\n",
    "_data = []\n",
    "_targets = []\n",
    "for target in targets:\n",
    "    for file in os.listdir(f\"{dataset_dir}/{target}\"):\n",
    "        _data.append(load_and_preprocess(f\"{dataset_dir}/{target}/{file}\"))\n",
    "        _targets.append(target_encoding[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a130943-6475-4bdf-ae37-bc9c84384125",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Estimated processed dataset_size: {len(_data) * (3 * processed_image_size**2) * 4 // 10**6 } MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e210641c-1b69-47df-b52b-06a565e6151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(_data, _targets, test_size=0.1, random_state=42, shuffle=True, stratify=_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Implementing augmentations\n",
    "augmentation_pipeline = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(p=0.1),\n",
    "    transforms.RandomVerticalFlip(p=0.1)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a621033d-78ec-4e46-a6b1-347a79317277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a simple baseline - a ResNet model\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                               kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels,\n",
    "                               kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "\n",
    "        self.downsample = False\n",
    "        if in_channels != out_channels:\n",
    "            self.downsample = True\n",
    "            self.downsample_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                               kernel_size=1, stride=1, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, _input: Tensor) -> Tensor:\n",
    "        identity = _input\n",
    "        if self.downsample:\n",
    "            identity = self.downsample_layer(identity)\n",
    "\n",
    "        output = self.conv1(_input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.activation(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output += identity\n",
    "        output = self.activation(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class MyResNet(nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "\n",
    "    def __init__(self, input_channels: int, layers: list[tuple[int, int]], num_of_classes: int, initial_layers:\n",
    "    Optional[nn.Module] = None):\n",
    "        super().__init__()\n",
    "\n",
    "        if initial_layers is None:\n",
    "            initial_layers = nn.Identity()\n",
    "        self.initial_layers = initial_layers\n",
    "\n",
    "        self.layers = nn.Sequential()\n",
    "        for layer_id, layer in enumerate(layers):\n",
    "            num_of_blocks, channels_per_block = layer\n",
    "            for block_id in range(num_of_blocks):\n",
    "                if block_id == 0:\n",
    "                    if layer_id == 0:\n",
    "                        in_channels = input_channels\n",
    "                    else:\n",
    "                        in_channels = layers[layer_id - 1][1]\n",
    "                else:\n",
    "                    in_channels = channels_per_block\n",
    "                self.layers.add_module(f\"ResBlock{layer_id}_{block_id}\",\n",
    "                                       ResBlock(in_channels=in_channels, out_channels=channels_per_block))\n",
    "\n",
    "            if layer_id != len(layers) - 1:\n",
    "                self.layers.add_module(f\"pool{layer_id}\", nn.MaxPool2d(2))\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(in_features=layers[-1][1], out_features=num_of_classes)\n",
    "\n",
    "\n",
    "    def forward(self, _input: Tensor) -> Tensor:\n",
    "        output = self.initial_layers(_input)\n",
    "        output = self.layers(output)\n",
    "        output = self.avg_pool(output)\n",
    "        output = torch.flatten(output, 1)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = MyResNet(input_channels=3, layers=[(4, 64), (4, 128)], num_of_classes=8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Напишем стандартный код, который можно использовать для обучения моделек:\n",
    "# TODO:\n",
    "# add augmentation during training\n",
    "\n",
    "def trainer(number_of_epochs,\n",
    "            dataset,\n",
    "            val_dataset,\n",
    "            batch_size,\n",
    "            model,\n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            writer,\n",
    "            lr = 0.001):\n",
    "    def make_val_report(iteration):\n",
    "        report = calculate_val_performance(model, DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=8))\n",
    "        def report_avg(which_avg):\n",
    "            for metric in report[which_avg]:\n",
    "                if metric != 'support':\n",
    "                    writer.add_scalar(f'metrics/{which_avg}/{metric}', report[which_avg][metric], iteration)\n",
    "        report_avg('weighted avg')\n",
    "        report_avg('macro avg')\n",
    "        writer.add_scalar(f'metrics/accuracy', report['accuracy'], iteration)\n",
    "\n",
    "\n",
    "    optima = optimizer(model.parameters(), lr=lr)\n",
    "\n",
    "    iterations = tqdm(range(number_of_epochs), desc='epoch')\n",
    "    iterations.set_postfix({'train epoch loss': np.nan})\n",
    "    for it in iterations:\n",
    "        epoch_loss = train_epoch(train_generator=DataLoader(dataset, batch_size, shuffle=True, num_workers=8),\n",
    "                    model=model,\n",
    "                    loss_function=loss_function,\n",
    "                    optimizer=optima)\n",
    "\n",
    "        iterations.set_postfix({'train epoch loss': epoch_loss})\n",
    "        writer.add_scalar('metrics/train_loss', epoch_loss, it)\n",
    "        make_val_report(it)\n",
    "\n",
    "\n",
    "def train_epoch(train_generator, model, loss_function, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    for x, y in train_generator:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x.to(model.device))\n",
    "\n",
    "        loss = loss_function(output, y.to(model.device))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.cpu().item()\n",
    "        total += 1\n",
    "\n",
    "    return epoch_loss/total\n",
    "\n",
    "\n",
    "def calculate_val_performance(model, val_dataset):\n",
    "    model.eval()\n",
    "\n",
    "    y_pred = [int(torch.argmax(model(x.to(model.device)).cpu())) for x, y in val_dataset]\n",
    "    y_target = [int(y) for x, y in val_dataset]\n",
    "\n",
    "    print(y_pred, y_target)\n",
    "\n",
    "    return sklearn.metrics.classification_report(y_target, y_pred, output_dict=True, zero_division=0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc5b076-4d49-4f14-9f26-3c6c7942f87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model.to('cuda')\n",
    "trainer(number_of_epochs=10,\n",
    "        dataset=list(zip(x_train, y_train)),\n",
    "        val_dataset=list(zip(x_test, y_test)),\n",
    "        batch_size = 16,\n",
    "        model=model,\n",
    "        loss_function=nn.CrossEntropyLoss(),\n",
    "        optimizer=torch.optim.Adam,\n",
    "        writer=SummaryWriter(log_dir='/local/tmp/logs/BG_application/resnet'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
